{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e29232d",
   "metadata": {},
   "source": [
    "\n",
    "# Análisis de Evasión — TelecomX (JSON → Pandas → Limpieza → Visualización → Informe)\n",
    "\n",
    "**Instrucciones rápidas**  \n",
    "- Ejecuta las celdas de arriba hacia abajo.  \n",
    "- La notebook descarga el JSON desde la URL pública, limpia los datos, calcula métricas y crea un informe final en Markdown en `informe_final.md`.\n",
    "\n",
    "**Fuente de datos (puedes cambiarla si lo necesitas):**\n",
    "```\n",
    "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/refs/heads/main/TelecomX_Data.json\n",
    "```\n",
    "\n",
    "> Nota: Esta notebook intenta detectar automáticamente la columna objetivo relacionada con *evasión / churn*. Si no la encuentra, seguirá con análisis descriptivo general y te indicará qué hacer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5614ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 1) Importaciones y Configuración\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "# Configuración de pandas\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 150)\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "URL = \"https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/refs/heads/main/TelecomX_Data.json\"  # @param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34298ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 2) Cargar JSON → DataFrame\n",
    "def load_json_to_df(url: str) -> pd.DataFrame:\n",
    "    # Intento 1: pandas.read_json directo\n",
    "    try:\n",
    "        df = pd.read_json(url, dtype=False)\n",
    "        if isinstance(df, pd.DataFrame) and df.shape[0] > 0:\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(\"read_json falló:\", e)\n",
    "\n",
    "    # Intento 2: usar requests y json.loads\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        if isinstance(data, list):\n",
    "            return pd.DataFrame(data)\n",
    "        elif isinstance(data, dict):\n",
    "            # Si es un dict con una clave principal con lista\n",
    "            for v in data.values():\n",
    "                if isinstance(v, list):\n",
    "                    return pd.DataFrame(v)\n",
    "            # Si no, normalizar\n",
    "            return pd.json_normalize(data)\n",
    "    except Exception as e:\n",
    "        print(\"requests/json falló:\", e)\n",
    "\n",
    "    raise RuntimeError(\"No se pudo cargar el JSON en un DataFrame. Verifica la URL o el formato.\")\n",
    "\n",
    "df_raw = load_json_to_df(URL)\n",
    "print(\"Cargado: filas =\", len(df_raw), \" | columnas =\", df_raw.shape[1])\n",
    "df_raw.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbecaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 3) Normalizar nombres de columnas\n",
    "def normalize_colname(c: str) -> str:\n",
    "    c = c.strip()\n",
    "    c = re.sub(r\"[^\\w\\s]\", \"_\", c, flags=re.UNICODE)\n",
    "    c = re.sub(r\"\\s+\", \"_\", c, flags=re.UNICODE)\n",
    "    c = c.lower()\n",
    "    c = re.sub(r\"_+\", \"_\", c)\n",
    "    return c.strip(\"_\")\n",
    "\n",
    "df = df_raw.copy()\n",
    "df.columns = [normalize_colname(c) for c in df.columns]\n",
    "print(\"Columnas normalizadas:\", list(df.columns)[:20])\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb99010",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 4) Calidad de datos: tipos, nulos, duplicados, formatos\n",
    "profile = {}\n",
    "\n",
    "# Tipos iniciales\n",
    "profile[\"dtypes_iniciales\"] = df.dtypes.astype(str).to_dict()\n",
    "\n",
    "# Conteo de nulos\n",
    "nulls = df.isna().sum().sort_values(ascending=False)\n",
    "profile[\"nulos_por_columna\"] = nulls.to_dict()\n",
    "\n",
    "# Duplicados\n",
    "duplicated_rows = df.duplicated().sum()\n",
    "profile[\"filas_duplicadas\"] = int(duplicated_rows)\n",
    "\n",
    "# Heurísticas de conversión de tipos\n",
    "date_like = [c for c in df.columns if re.search(r\"(fecha|date|_at|_on)$\", c)]\n",
    "numeric_like = [c for c in df.columns if re.search(r\"(monto|charge|importe|total|balance|price|cost|amount|tenure|minutes|calls|gb|data|count|num|porcentaje|pct|rate)\", c)]\n",
    "bool_like = [c for c in df.columns if re.search(r\"(si|sí|no|true|false|yes|no|churn|evad|evas|cancel|active|inactive|status)\", c)]\n",
    "\n",
    "# Convertir fechas\n",
    "for c in date_like:\n",
    "    try:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Convertir numéricos\n",
    "for c in numeric_like:\n",
    "    if df[c].dtype == \"object\":\n",
    "        # Remover símbolos comunes y convertir\n",
    "        df[c] = (\n",
    "            df[c]\n",
    "            .astype(str)\n",
    "            .str.replace(\",\", \"\", regex=False)\n",
    "            .str.replace(\"$\", \"\", regex=False)\n",
    "            .str.replace(\"%\", \"\", regex=False)\n",
    "        )\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Convertir booleanos (Yes/No, Sí/No, True/False)\n",
    "def to_bool_series(s: pd.Series) -> Optional[pd.Series]:\n",
    "    if s.dtype != \"object\":\n",
    "        return None\n",
    "    mapping = {\n",
    "        \"yes\": True, \"no\": False,\n",
    "        \"si\": True, \"sí\": True, \"no.\": False, \"n\": False, \"s\": True,\n",
    "        \"true\": True, \"false\": False,\n",
    "        \"1\": True, \"0\": False\n",
    "    }\n",
    "    vals = s.dropna().astype(str).str.strip().str.lower().unique()\n",
    "    # Si tiene pocos valores y encajan en el mapeo, convertir\n",
    "    if len(vals) <= 6 and all(v in mapping or v in [\"\", \"nan\"] for v in vals):\n",
    "        return s.astype(str).str.strip().str.lower().map(mapping).astype(\"boolean\")\n",
    "    return None\n",
    "\n",
    "for c in bool_like:\n",
    "    conv = to_bool_series(df[c])\n",
    "    if conv is not None:\n",
    "        df[c] = conv\n",
    "\n",
    "# Eliminar duplicados exactos\n",
    "if duplicated_rows > 0:\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "profile[\"dtypes_finales\"] = df.dtypes.astype(str).to_dict()\n",
    "profile[\"shape_final\"] = df.shape\n",
    "\n",
    "print(\"Chequeos completos.\")\n",
    "print(\"Duplicados eliminados:\", duplicated_rows)\n",
    "print(\"Nulos por columna (top 10):\")\n",
    "nulls.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 5) Detección automática de 'evasión' (columna objetivo)\n",
    "candidate_patterns = [\n",
    "    r\"churn\", r\"evad\", r\"evas\", r\"cancel\", r\"aband\", r\"desert\", r\"default\",\n",
    "    r\"fraud\", r\"attrition\", r\"baja\", r\"leav\"\n",
    "]\n",
    "\n",
    "target_col = None\n",
    "for c in df.columns:\n",
    "    if any(re.search(p, c) for p in candidate_patterns):\n",
    "        # preferir columnas binarias\n",
    "        nunique = df[c].nunique(dropna=True)\n",
    "        if nunique <= 5:\n",
    "            target_col = c\n",
    "            break\n",
    "\n",
    "if target_col is None:\n",
    "    # fallback: buscar columnas booleanas\n",
    "    for c in df.columns:\n",
    "        if str(df[c].dtype) in [\"bool\", \"boolean\"]:\n",
    "            if any(re.search(p, c) for p in candidate_patterns) or df[c].nunique(dropna=True) == 2:\n",
    "                target_col = c\n",
    "                break\n",
    "\n",
    "print(\"Columna objetivo detectada:\", target_col)\n",
    "if target_col is not None:\n",
    "    print(\"Distribución de clases:\")\n",
    "    print(df[target_col].value_counts(dropna=False))\n",
    "else:\n",
    "    print(\"No se detectó automáticamente una columna clara de evasión. Se continuará con análisis general.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e2ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 6) Relevancia de columnas vs evasión\n",
    "relevance_table = pd.DataFrame()\n",
    "\n",
    "if target_col is not None:\n",
    "    # Preparación de features\n",
    "    y = df[target_col].astype(\"float\").fillna(-1)  # -1 para NaN (se excluirá)\n",
    "    mask = y.isin([0.0, 1.0])\n",
    "    y = y[mask]\n",
    "    X = df.loc[mask].drop(columns=[target_col]).copy()\n",
    "\n",
    "    # Codificación simple: numéricos tal cual; categóricos → códigos\n",
    "    X_enc = pd.DataFrame(index=X.index)\n",
    "    for c in X.columns:\n",
    "        if pd.api.types.is_numeric_dtype(X[c]):\n",
    "            X_enc[c] = X[c].fillna(X[c].median())\n",
    "        else:\n",
    "            X_enc[c] = X[c].astype(\"category\").cat.codes.replace(-1, np.nan)\n",
    "            X_enc[c] = X_enc[c].fillna(X_enc[c].median())\n",
    "\n",
    "    # Mutual information (sin scikit, estimador discretizado simple)\n",
    "    def discretize(s: pd.Series, bins=10):\n",
    "        try:\n",
    "            return pd.qcut(s, q=min(bins, s.nunique()), duplicates='drop').astype(str)\n",
    "        except Exception:\n",
    "            return s.astype(str)\n",
    "\n",
    "    def mi_discrete(x: pd.Series, y: pd.Series) -> float:\n",
    "        # cálculo MI básico con tablas de contingencia\n",
    "        xy = pd.crosstab(x, y)\n",
    "        px = xy.sum(axis=1) / xy.values.sum()\n",
    "        py = xy.sum(axis=0) / xy.values.sum()\n",
    "        pxy = xy / xy.values.sum()\n",
    "        mi = 0.0\n",
    "        for i in pxy.index:\n",
    "            for j in pxy.columns:\n",
    "                pij = pxy.loc[i, j]\n",
    "                if pij > 0:\n",
    "                    mi += pij * math.log(pij / (px[i] * py[j] + 1e-12) + 1e-12)\n",
    "        return float(mi)\n",
    "\n",
    "    scores = []\n",
    "    for c in X_enc.columns:\n",
    "        xv = X_enc[c]\n",
    "        xv_disc = discretize(xv)\n",
    "        try:\n",
    "            score = mi_discrete(xv_disc, y)\n",
    "        except Exception:\n",
    "            score = np.nan\n",
    "        scores.append((c, score))\n",
    "\n",
    "    relevance_table = pd.DataFrame(scores, columns=[\"columna\", \"mi_discreta\"]).sort_values(\"mi_discreta\", ascending=False)\n",
    "    display(relevance_table.head(20))\n",
    "else:\n",
    "    print(\"Sin columna objetivo, se omite la tabla de relevancia.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42474ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 7) Crear columna 'Cuentas_Diarias' (valor diario estimado)\n",
    "def create_cuentas_diarias(df: pd.DataFrame) -> pd.Series:\n",
    "    # Heurística: si existe monthlycharges/monto_mensual => dividir entre 30\n",
    "    monthly_cols = [c for c in df.columns if re.search(r\"(monthly|mensual)\", c)]\n",
    "    total_cols   = [c for c in df.columns if re.search(r\"(total|acumulado)\", c)]\n",
    "    tenure_cols  = [c for c in df.columns if re.search(r\"(tenure|meses|months)\", c)]\n",
    "    daily = pd.Series(np.nan, index=df.index, dtype=\"float\")\n",
    "\n",
    "    # Caso 1: monthly charges\n",
    "    for c in monthly_cols:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            daily = df[c] / 30.0\n",
    "            break\n",
    "\n",
    "    # Caso 2: total / tenure\n",
    "    if daily.isna().all() and total_cols and tenure_cols:\n",
    "        for tc in total_cols:\n",
    "            for tn in tenure_cols:\n",
    "                if pd.api.types.is_numeric_dtype(df[tc]) and pd.api.types.is_numeric_dtype(df[tn]):\n",
    "                    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                        est = df[tc] / (df[tn] * 30.0)\n",
    "                        est.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "                        if est.notna().mean() > daily.notna().mean():\n",
    "                            daily = est\n",
    "\n",
    "    return daily\n",
    "\n",
    "df[\"cuentas_diarias\"] = create_cuentas_diarias(df)\n",
    "df[\"cuentas_diarias\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 8) Estadística descriptiva (media, mediana, desviación estándar)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "desc_stats = pd.DataFrame({\n",
    "    \"media\": df[numeric_cols].mean(),\n",
    "    \"mediana\": df[numeric_cols].median(),\n",
    "    \"desv_std\": df[numeric_cols].std(ddof=1),\n",
    "})\n",
    "display(desc_stats.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ad833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 9) Visualizaciones de evasión\n",
    "# NOTA: Reglas solicitadas: usar matplotlib, una figura por gráfico, sin especificar colores.\n",
    "import os\n",
    "\n",
    "os.makedirs(\"figuras\", exist_ok=True)\n",
    "\n",
    "if target_col is not None:\n",
    "    # 9.1 Distribución de la evasión\n",
    "    plt.figure()\n",
    "    df[target_col].value_counts(dropna=False).sort_index().plot(kind=\"bar\")\n",
    "    plt.title(\"Distribución de Evasión (objetivo)\")\n",
    "    plt.xlabel(target_col)\n",
    "    plt.ylabel(\"Número de registros\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"figuras/distribucion_evasion.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # 9.2 Evasión por categorías (top 3 variables categóricas más relevantes)\n",
    "    cat_cols = [c for c in df.columns if c != target_col and not pd.api.types.is_numeric_dtype(df[c])]\n",
    "    # Seleccionamos hasta 3 columnas categóricas con mayor MI (si existe tabla)\n",
    "    top_cats = []\n",
    "    if 'relevance_table' in globals() and isinstance(relevance_table, pd.DataFrame) and not relevance_table.empty:\n",
    "        for _, row in relevance_table.iterrows():\n",
    "            c = row[\"columna\"]\n",
    "            if c in cat_cols:\n",
    "                top_cats.append(c)\n",
    "            if len(top_cats) >= 3:\n",
    "                break\n",
    "    else:\n",
    "        top_cats = cat_cols[:3]\n",
    "\n",
    "    for c in top_cats:\n",
    "        plt.figure()\n",
    "        rates = df.groupby(c)[target_col].mean()\n",
    "        rates.plot(kind=\"bar\")\n",
    "        plt.title(f\"Tasa de evasión por {c}\")\n",
    "        plt.xlabel(c)\n",
    "        plt.ylabel(\"Tasa de evasión\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"figuras/tasa_evasion_por_{c}.png\")\n",
    "        plt.show()\n",
    "\n",
    "    # 9.3 Si existe 'cuentas_diarias', ver distribución por estado de evasión\n",
    "    if \"cuentas_diarias\" in df.columns and pd.api.types.is_numeric_dtype(df[\"cuentas_diarias\"]):\n",
    "        plt.figure()\n",
    "        df.boxplot(column=\"cuentas_diarias\", by=target_col)\n",
    "        plt.title(\"Cuentas Diarias por estado de evasión\")\n",
    "        plt.suptitle(\"\")\n",
    "        plt.xlabel(target_col)\n",
    "        plt.ylabel(\"Cuentas Diarias (estimación)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"figuras/cuentas_diarias_por_evasion.png\")\n",
    "        plt.show()\n",
    "else:\n",
    "    # Visualización general si no hay target\n",
    "    plt.figure()\n",
    "    df.isna().sum().sort_values(ascending=False).head(20).plot(kind=\"bar\")\n",
    "    plt.title(\"Valores nulos por columna (Top 20)\")\n",
    "    plt.xlabel(\"Columna\")\n",
    "    plt.ylabel(\"Nulos\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"figuras/nulos_top20.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title 10) Informe final (Markdown)\n",
    "lines = []\n",
    "lines.append(\"# Informe Final — Análisis de Evasión (TelecomX)\\n\")\n",
    "lines.append(\"## 1. Resumen de la carga y estructura\\n\")\n",
    "lines.append(f\"- Filas: **{df.shape[0]}**, Columnas: **{df.shape[1]}**\\n\")\n",
    "lines.append(\"### Columnas (primeras 30)\\n\")\n",
    "cols_list = \", \".join(list(df.columns)[:30])\n",
    "lines.append(f\"{cols_list}\\n\")\n",
    "\n",
    "lines.append(\"## 2. Calidad de datos\\n\")\n",
    "lines.append(f\"- Filas duplicadas eliminadas: **{profile.get('filas_duplicadas', 0)}**\\n\")\n",
    "lines.append(\"### Nulos por columna (Top 10)\\n\")\n",
    "lines.append(df.isna().sum().sort_values(ascending=False).head(10).to_markdown())\n",
    "\n",
    "lines.append(\"\\n## 3. Tipos de datos (antes → después)\\n\")\n",
    "dtypes_i = profile.get(\"dtypes_iniciales\", {})\n",
    "dtypes_f = profile.get(\"dtypes_finales\", {})\n",
    "pairs = []\n",
    "for c in df.columns:\n",
    "    di = dtypes_i.get(c, \"?\")\n",
    "    dfinal = dtypes_f.get(c, \"?\")\n",
    "    if di != dfinal:\n",
    "        pairs.append(f\"- `{c}`: {di} → {dfinal}\")\n",
    "if not pairs:\n",
    "    lines.append(\"- No hubo cambios sustanciales en los tipos inferidos.\\n\")\n",
    "else:\n",
    "    lines.extend(pairs)\n",
    "\n",
    "lines.append(\"\\n## 4. Columna objetivo (evasión)\\n\")\n",
    "if 'target_col' in globals() and target_col is not None:\n",
    "    lines.append(f\"- Objetivo detectado: **`{target_col}`**\\n\")\n",
    "    dist = df[target_col].value_counts(dropna=False).to_frame(\"conteo\")\n",
    "    lines.append(\"### Distribución de clases\\n\")\n",
    "    lines.append(dist.to_markdown())\n",
    "else:\n",
    "    lines.append(\"- **No se detectó** automáticamente una columna de evasión. Revisa posibles columnas como `churn`, `evasión`, `cancelado`, etc.\\n\")\n",
    "\n",
    "lines.append(\"\\n## 5. Variables relevantes\\n\")\n",
    "if 'relevance_table' in globals() and isinstance(relevance_table, pd.DataFrame) and not relevance_table.empty:\n",
    "    lines.append(relevance_table.head(15).to_markdown(index=False))\n",
    "else:\n",
    "    lines.append(\"- Sin variable objetivo, no se calcularon relevancias.\")\n",
    "\n",
    "lines.append(\"\\n## 6. Cuentas_Diarias\\n\")\n",
    "if \"cuentas_diarias\" in df.columns:\n",
    "    desc_cd = df[\"cuentas_diarias\"].describe().to_frame().to_markdown()\n",
    "    lines.append(\"- Columna creada: `cuentas_diarias` (estimación)\")\n",
    "    lines.append(desc_cd)\n",
    "else:\n",
    "    lines.append(\"- No fue posible crear `cuentas_diarias` por falta de columnas monetarias/tenencia.\")\n",
    "\n",
    "lines.append(\"\\n## 7. Estadística descriptiva\\n\")\n",
    "lines.append(desc_stats.head(30).to_markdown())\n",
    "\n",
    "lines.append(\"\\n## 8. Visualizaciones generadas\\n\")\n",
    "figs = []\n",
    "if os.path.exists(\"figuras\"):\n",
    "    for f in sorted(os.listdir(\"figuras\")):\n",
    "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".webp\")):\n",
    "            figs.append(f\"- `figuras/{f}`\")\n",
    "if figs:\n",
    "    lines.extend(figs)\n",
    "else:\n",
    "    lines.append(\"- No se generaron figuras (posiblemente por falta de columna objetivo).\")\n",
    "\n",
    "lines.append(\"\\n## 9. Recomendaciones siguientes\\n\")\n",
    "lines.append(\"- Validar manualmente la columna objetivo de evasión si no fue detectada.\")\n",
    "lines.append(\"- Revisar categorías con altas tasas de evasión para diseñar retención.\")\n",
    "lines.append(\"- Evaluar modelos predictivos (árboles, logística) si el objetivo está claro.\")\n",
    "lines.append(\"- Añadir variables de negocio (descuentos, quejas, antigüedad) para mejor señal.\")\n",
    "\n",
    "with open(\"/mnt/data/informe_final.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Informe generado en /mnt/data/informe_final.md\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
